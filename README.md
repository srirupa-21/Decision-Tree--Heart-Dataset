# ğŸ«€ Heart Disease Prediction using Decision Tree

This project demonstrates how to build, train, evaluate, and visualize a **Decision Tree Classifier** using the **Heart Disease dataset**.  
It is designed for **beginners** to understand machine learning workflows step by step.

---

## ğŸ“Œ Project Overview

The goal of this project is to predict whether a person has heart disease based on medical attributes such as age, cholesterol level, blood pressure, and other clinical features using a **Decision Tree model**.

---

## ğŸ“‚ Dataset

- **Dataset Name:** Heart Disease Dataset  
- **Target Column:** `target`  
  - `0` â†’ No heart disease  
  - `1` â†’ Heart disease present  

The dataset contains both **numerical and categorical features**, making it suitable for Decision Tree models.

---

## ğŸ› ï¸ Technologies Used

- Python  
- Pandas  
- NumPy  
- Scikit-learn  
- Matplotlib  

---

## ğŸ§  Machine Learning Workflow

### 1ï¸âƒ£ Data Exploration
- Displayed dataset shape and column names  
- Viewed first 5 rows  
- Identified target and feature columns  
- Checked missing values and data types  

---

### 2ï¸âƒ£ Data Preprocessing
- Handled missing values (if any)  
- Separated features (**X**) and target (**y**)  
- Split data into:
  - Training set: **80%**
  - Testing set: **20%**
- Used `random_state = 42` for reproducibility  

---

### 3ï¸âƒ£ Model Building
- Built a **Decision Tree Classifier**
- Used:
  - `criterion = 'gini'`
  - `random_state = 42`
- Trained the model on training data  
- Predicted results on test data  

---

### 4ï¸âƒ£ Model Evaluation
- Calculated:
  - Accuracy Score  
  - Confusion Matrix  
  - Classification Report  
- Achieved **~98â€“99% accuracy**  
- Both classes were predicted very well  

---

### 5ï¸âƒ£ Tree Depth Experiment
Tested multiple values of `max_depth`:
- `max_depth = 2` â†’ Underfitting  
- `max_depth = 5` â†’ Best performance  
- `max_depth = None` â†’ Overfitting  

---

### 6ï¸âƒ£ Tree Visualization
- Visualized the best-performing Decision Tree  
- Included:
  - Feature names  
  - Class names  
- Made the model easy to interpret  

---

### 7ï¸âƒ£ Hyperparameter Comparison
- Compared:
  - `criterion = 'gini'` vs `criterion = 'entropy'`
- Tested different values of:
  - `min_samples_leaf`
- Observed that:
  - Gini and Entropy give similar results  
  - Moderate `min_samples_leaf` improves generalization  

---

## ğŸ“Š Key Results

- **Accuracy:** ~98â€“99%  
- **Best Model:** Decision Tree with controlled depth  
- **Observation:** Decision Trees can overfit if not properly tuned  

---

## âœ… Conclusion

- Decision Trees are highly interpretable and suitable for medical datasets  
- Parameter tuning (`max_depth`, `min_samples_leaf`) is essential  
- Ensemble methods can further improve performance  
- This project provides a strong foundation for understanding tree-based models  

---

## ğŸ“ Files in Repository

- `Heart_Disease_Decision_Tree.ipynb` â€“ Complete implementation  
- `heart.csv` â€“ Dataset  
- `README.md` â€“ Project documentation  

---

## ğŸš€ Future Improvements

- Try **Random Forest** or **Gradient Boosting**  
- Perform **cross-validation**  
- Add **feature importance analysis**  
